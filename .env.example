# Discord Bot Configuration
DISCORD_BOT_TOKEN=your_bot_token_here
DISCORD_GUILD_ID=867551208286060594

# IMPORTANT: Single channel scraping/monitoring
# The bot will ONLY collect data from and respond in this ONE channel
# Get channel ID: Right-click channel → Copy Channel ID (requires Developer Mode)
DISCORD_CHANNEL_ID=867551208738127882

# Data Collection Settings
REQUESTS_PER_SECOND=5
MIN_MESSAGE_TOKENS=1
MAX_MESSAGE_TOKENS=512
EXCLUDE_BOT_MESSAGES=true
EXCLUDE_SYSTEM_MESSAGES=true

# Model Configuration
MODEL_NAME=mistralai/Mistral-7B-v0.3
ADAPTER_PATH=./adapters/discord-lora
CONTEXT_TOKENS=384  # Reduced for 11GB VRAM (was 512)
MAX_NEW_TOKENS=100
TEMPERATURE=0.7
TOP_P=0.9
TOP_K=40
REPETITION_PENALTY=1.1
LOAD_IN_4BIT=true  # CRITICAL for 11GB VRAM

# Memory Settings
SHORT_TERM_WINDOW=20
SUMMARIZE_INTERVAL=5
RAG_TOP_K=5
SUMMARIZATION_MODEL=facebook/bart-large-cnn

# Vector Database
VECTOR_DB_PATH=./data/vector_db
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Training Settings
TRAINING_DATA_PATH=./data/training_data.jsonl
LEARNING_RATE=2.5e-4  # Increased for larger batch size
EPOCHS=1  # For 63k pre-filtered messages - DO NOT increase (overfitting risk)
BATCH_SIZE=1
GRADIENT_ACCUMULATION_STEPS=32  # Increased from 16 for 2× speedup (18hrs instead of 35hrs)
GRADIENT_CHECKPOINTING=true  # Required for 11GB VRAM during training
USE_FP16=true  # Mixed precision training for 30% speedup (RTX 2080 Ti compatible)

# System Settings
LOG_LEVEL=INFO
LOG_FILE=./logs/bot.log
CHECKPOINT_PATH=./data/backfill_checkpoint.json

# Performance
ENABLE_QUANTIZATION=true  # MUST BE TRUE for 11GB VRAM
DEVICE=cuda
USE_FLASH_ATTENTION=false  # Set to true if you install flash-attn (faster inference)
# Device options: cuda, cpu, mps (for Mac)
