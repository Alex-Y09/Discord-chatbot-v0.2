# ============================================
# PHASE 1: DATA COLLECTION (Start Here!)
# ============================================

# Discord Bot Credentials
DISCORD_BOT_TOKEN=your_bot_token_here
DISCORD_GUILD_ID=your_server_id_here

# IMPORTANT: Single channel operation
# The bot will ONLY collect data from this ONE channel
# To get channel ID: Right-click channel → Copy Channel ID (requires Developer Mode in Discord settings)
DISCORD_CHANNEL_ID=your_channel_id_here

# Data Collection Settings
REQUESTS_PER_SECOND=40  # Fast collection (within Discord limits, can reduce to 20 if rate limited)
MAX_MESSAGES=65000  # Collect 65k (expect ~63k after filtering)
ENABLE_CHECKPOINT=true  # Resume if interrupted
CHECKPOINT_INTERVAL=1000  # Save progress every 1000 messages

# ============================================
# PHASE 2: TRAINING (Configure later)
# ============================================

# Training Data
TRAINING_DATA_PATH=./data/training_data.jsonl

# Training Settings (OPTIMIZED for RTX 2080 Ti - 13-18 hour training!)
LEARNING_RATE=2.5e-4  # Adjusted for larger effective batch size
EPOCHS=1  # For 63k pre-filtered messages - DO NOT increase (overfitting risk)
BATCH_SIZE=1
GRADIENT_ACCUMULATION_STEPS=32  # Increased from 16 for 2× speedup
GRADIENT_CHECKPOINTING=true  # Required for 11GB VRAM during training
USE_FP16=true  # Mixed precision training for 1.3× speedup (RTX 2080 Ti compatible)

# Result: 13-18 hours instead of 35 hours! ⚡
# Quality: Identical to baseline (zero quality loss)

# ============================================
# PHASE 3: DEPLOYMENT (Configure later)
# ============================================

# Model Configuration
MODEL_NAME=mistralai/Mistral-7B-v0.3
ADAPTER_PATH=./adapters/discord-lora
CONTEXT_TOKENS=384  # Reduced for 11GB VRAM (was 512)
MAX_NEW_TOKENS=100
TEMPERATURE=0.7
TOP_P=0.9
TOP_K=40
REPETITION_PENALTY=1.1
LOAD_IN_4BIT=true  # CRITICAL for 11GB VRAM

# Memory Settings
SHORT_TERM_WINDOW=20
SUMMARIZE_INTERVAL=5
RAG_TOP_K=5
SUMMARIZATION_MODEL=facebook/bart-large-cnn

# Vector Database
VECTOR_DB_PATH=./data/vector_db
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# System Settings
LOG_LEVEL=INFO
LOG_FILE=./logs/bot.log
CHECKPOINT_PATH=./data/backfill_checkpoint.json
DEVICE=cuda

# Performance
ENABLE_QUANTIZATION=true  # MUST BE TRUE for 11GB VRAM
DEVICE=cuda
USE_FLASH_ATTENTION=false  # Set to true if you install flash-attn (faster inference)
# Device options: cuda, cpu, mps (for Mac)
